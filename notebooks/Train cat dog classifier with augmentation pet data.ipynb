{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Conv2D, MaxPooling2D\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from keras import optimizers\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "# from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from keras.applications.xception import Xception\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import NASNetLarge, InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from keras.preprocessing import image\n",
    "import os, shutil\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bread_labels = pd.read_csv('../pet_data/breed_labels.csv')\n",
    "color_labels = pd.read_csv('../pet_data/color_labels.csv')\n",
    "state_labels = pd.read_csv('../pet_data/state_labels.csv')\n",
    "test_sample_submission = pd.read_csv('../pet_data/test/sample_submission.csv')\n",
    "test = pd.read_csv('../pet_data/test/test.csv')\n",
    "train = pd.read_csv('../pet_data/train.csv')\n",
    "train['dataset_type'] = 'train'\n",
    "test['dataset_type'] = 'test'\n",
    "all_data = pd.concat([train, test])\n",
    "train_folder = '../pet_data/train_images/'\n",
    "test_folder = '../pet_data/test_images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = [f for f in os.listdir(train_folder) if os.path.isfile(os.path.join(train_folder, f))]\n",
    "test_images = [f for f in os.listdir(test_folder) if os.path.isfile(os.path.join(test_folder, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images.sort()\n",
    "test_images.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Animal'] = train['Type'].apply(lambda x: 'Dog' if x == 1 else 'Cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_id_adopt_rate = pd.DataFrame([train.PetID, train.AdoptionSpeed, train.Type, train.Animal]).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = []\n",
    "\n",
    "for image_name in os.listdir('../pet_data/train_images/'):\n",
    "    image_names.append(image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names_df = pd.DataFrame(image_names, columns=['image_name'])\n",
    "# image_names_df.sort_values(by=['image_name'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = []\n",
    "\n",
    "for image_id in image_names_df.image_name:\n",
    "    image_ids.append(image_id[:image_id.index('-')])\n",
    "    \n",
    "\n",
    "# image_ids = set(image_ids)\n",
    "image_ids = list(image_ids)\n",
    "image_ids.sort()\n",
    "len(image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names_dataf = pd.DataFrame(image_ids, columns=['PetID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids2 = []\n",
    "\n",
    "for image_id in image_names_df.image_name:\n",
    "    image_ids2.append(image_id)\n",
    "    \n",
    "image_ids2.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_images = pd.merge(image_names_dataf, pet_id_adopt_rate, on=['PetID'], how='inner')\n",
    "# merged_images.sort_values('PetID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids2 = []\n",
    "\n",
    "for image_id in image_names_df.image_name:\n",
    "    image_ids2.append(image_id)\n",
    "    \n",
    "image_ids2.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_images.PetID = image_ids2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_dict = {'filename': [], 'class': [], 'type': []}\n",
    "\n",
    "for img in train_images:\n",
    "    generator_dict['filename'].append(img)\n",
    "for label in merged_images.AdoptionSpeed:\n",
    "    generator_dict['class'].append(str(label))\n",
    "for label_type in merged_images.Type:\n",
    "    generator_dict['type'].append(str(label_type))\n",
    "\n",
    "generator_df = pd.DataFrame(generator_dict)\n",
    "# generator_df.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_df.groupby('type').size().plot.bar()\n",
    "# generator_df = generator_df.drop(['class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('model accuracy')\n",
    "    plt.xlabel('accuracy')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('model loss')\n",
    "    plt.xlabel('loss')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(generator_df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "\n",
    "for index, row in test.iterrows():\n",
    "    if row.category == int(row.type):\n",
    "        i = i + 1\n",
    "\n",
    "print(i)\n",
    "print(len(test) - i)\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "def plot_history(history):\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('model accuracy')\n",
    "    plt.xlabel('accuracy')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('model loss')\n",
    "    plt.xlabel('loss')\n",
    "    plt.legend(['train', 'validation'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_datagen=ImageDataGenerator(\n",
    "    rescale=1./255.,\n",
    "    validation_split=0.25,\n",
    "    rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "def create_generator(subset):\n",
    "    return train_datagen.flow_from_dataframe(\n",
    "        train, \n",
    "        '../pet_data/train_images/', \n",
    "        x_col='filename',\n",
    "        y_col='type', \n",
    "        has_ext=True,  # If image extension is given in x_col\n",
    "        target_size=(150, 150), \n",
    "        color_mode='rgb',\n",
    "        class_mode='binary', \n",
    "        batch_size=16, \n",
    "        shuffle=True, \n",
    "        seed=2018,\n",
    "        subset=subset\n",
    "    )\n",
    "\n",
    "train_generator = create_generator('training')\n",
    "valid_generator = create_generator('validation')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = models.Sequential()\n",
    "model2.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model2.add(layers.MaxPooling2D((2, 2)))\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dropout(0.5))\n",
    "model2.add(layers.Dense(512, activation='relu'))\n",
    "model2.add(layers.Dense(1, activation='sigmoid'))\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    'model.h5', \n",
    "    monitor='val_acc', \n",
    "    verbose=0, \n",
    "    save_best_only=True, \n",
    "    save_weights_only=False,\n",
    "    mode='auto'\n",
    ")\n",
    "\n",
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "\n",
    "history = model2.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=STEP_SIZE_TRAIN, \n",
    "    epochs=100,\n",
    "    callbacks=[checkpoint],\n",
    "    validation_data=valid_generator,\n",
    "#     use_multiprocessing=True,\n",
    "    validation_steps=STEP_SIZE_VALID,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model2.load_weights('model.h5')\n",
    "\n",
    "val_scores = model2.evaluate_generator(\n",
    "    generator=valid_generator,\n",
    "    steps=len(valid_generator),\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print('\\nValidation loss:', val_scores[0])\n",
    "print('Validation accuracy:', val_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_samples = test.shape[0]\n",
    "nb_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "        test, \n",
    "        '../pet_data/train_images/', \n",
    "        x_col='filename',\n",
    "        y_col=None, \n",
    "        target_size=(150, 150),\n",
    "        class_mode=None, \n",
    "        batch_size=16, \n",
    "        shuffle=True,\n",
    "        seed=2018,\n",
    "    )\n",
    "\n",
    "STEP_SIZE_TEST = test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model2.predict_generator(test_generator, steps=np.ceil(nb_samples/16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "test['probability'] = predict\n",
    "test['category'] = np.where(test['probability'] > threshold, 2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['category'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "\n",
    "sample_test = test.head(18)\n",
    "sample_test.head()\n",
    "plt.figure(figsize=(12, 24))\n",
    "i=1\n",
    "for index, row in sample_test.iterrows():\n",
    "    filename = row['filename']\n",
    "    category = row['category']\n",
    "    probability = row['probability']\n",
    "    img = load_img(train_folder + filename, target_size=(128, 128))\n",
    "    plt.subplot(6, 3, i)\n",
    "    i=i+1\n",
    "    plt.imshow(img)\n",
    "    plt.xlabel(filename + '(' + \"{}\".format(category) + ')' '(' + \"{}\".format(round(probability, 2)) + ')')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "        test, \n",
    "        '../pet_data/train_images/', \n",
    "        x_col='filename',\n",
    "        y_col='type', \n",
    "        has_ext=True,  # If image extension is given in x_col\n",
    "        target_size=(150, 150), \n",
    "        color_mode='rgb',\n",
    "        class_mode='binary', \n",
    "        batch_size=16, \n",
    "        shuffle=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "score = model2.evaluate_generator(test_generator, STEP_SIZE_TEST)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "probabilities = model2.predict_generator(test_generator, STEP_SIZE_TEST, verbose=1)\n",
    "probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([0] * 1032 + [1] * 1032)\n",
    "y_pred = probabilities > 0.5\n",
    "\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "probabilities = model2.predict_generator(test_generator, STEP_SIZE_TEST + 1, verbose=1)\n",
    "probabilities\n",
    "\n",
    "y_true = np.array([0] * 1033 + [1] * 1033)\n",
    "y_pred = probabilities > 0.5\n",
    "\n",
    "confusion_matrix(y_true, y_pred[:2066])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "#Confution Matrix and Classification Report\n",
    "Y_pred = model2.predict_generator(test_generator, 2067 // 16+1)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(test_generator.classes, probabilities))\n",
    "print('Classification Report')\n",
    "target_names = ['Cats', 'Dogs']\n",
    "print(classification_report(test_generator.classes, probabilities, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "def show_image_predictions(probabilities, direct):\n",
    "    for index, probability in enumerate(probabilities):\n",
    "        image_path = direct + \"/\" +test_generator.filenames[index]\n",
    "        img = mpimg.imread(image_path)\n",
    "    #     with open(TEST_FILE,\"a\") as fh:\n",
    "    #         fh.write(str(probability[0]) + \" for: \" + image_path + \"\\n\")\n",
    "        plt.imshow(img)\n",
    "        if probability > 0.5:\n",
    "            plt.title(\"%.2f\" % (probability[0]*100) + \"% dog in \" + image_path)\n",
    "        else:\n",
    "            plt.title(\"%.2f\" % ((1-probability[0])*100) + \"% cat\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='confusion matrix', cmap=plt.cm.Blues):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[: np.newaxis]\n",
    "        print('normalized confusion matrix')\n",
    "    else:\n",
    "        print('unnormalized confusion matrix')\n",
    "        \n",
    "    print(cm)\n",
    "    \n",
    "    thresh = cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                horizontalalignment='center',\n",
    "                color='white' if cm[i, j] > thresh else 'black'\n",
    "                )\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix(y_true, y_pred[:2066]), ['cat', 'dog'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# show_image_predictions(probabilities, '../pet_data/train_images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
